{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f64342b2-1033-4ec0-b67d-30c2ef9c52f3",
   "metadata": {},
   "source": [
    "# what is machine learning?\n",
    "\n",
    "- linear regression example\n",
    "    - plot the data\n",
    "    - simple regression\n",
    " \n",
    "- training, loss functions, learning rate, batch size, etc.\n",
    "- logistic regression example\n",
    "    - difference between classification and regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eb92e3-ade1-4dca-9943-1385cdab061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn import linear_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf9b2a6-6bbc-48d5-8535-ffa5a0d7ae90",
   "metadata": {},
   "source": [
    "Next, let's read in the first dataset that we will use for the exercise: {explanation}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5327f922-ec3f-4a9e-b0fe-b163b1c4b692",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/armaghdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a0008f-8844-4fa8-95ce-1ba156fdfe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot('sun', 'tmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9289dd-7cd4-4cf7-9bba-13020e9aaa1c",
   "metadata": {},
   "source": [
    "## linear regression\n",
    "\n",
    "Remember that a linear model with a single variable has the form:\n",
    "\n",
    "$$ y = \\beta + \\alpha x $$\n",
    "\n",
    "where $\\beta$ is the *intercept* of the line and $\\alpha$ is the *slope* of the line. \n",
    "\n",
    "The terminology often used in machine learning is a little bit different. The equation for a linear model is often written as:\n",
    "\n",
    "$$ \\hat{y} = b + wx $$\n",
    "\n",
    "where $\\hat{y}$ is the predicted value/label, $b$ is the *bias*, and $w$ is the *weight* of the feature $x$. Extending this to multiple features (variables), the form looks like:\n",
    "\n",
    "$$ \\hat{y} = b + w_1 x_1 + w_2 x_2 + \\cdots + w_n x_n = b + \\sum_i w_i x_i $$\n",
    "\n",
    "Where each feature $x_i$ has a corresponding weight $w_i$. \n",
    "\n",
    "For this first example, we will look at a model with a single feature (variable) - the relationship between {X and Y}.\n",
    "\n",
    "To begin, we first have to create a **LinearRegression** object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cd3498-6c57-4aac-87dc-4f9636d42412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a LinearRegression object\n",
    "model = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821aa504-85e9-4179-8e7e-c4fe6e6a8316",
   "metadata": {},
   "source": [
    "In `scikit-learn`, the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee0c3e9-c5ea-46fb-ba78-f5c00301cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model on our input data\n",
    "data = data.dropna(subset=['sun', 'tmax'], how='any')\n",
    "\n",
    "sun = data.sun.values.reshape(-1, 1)\n",
    "tmax = data.tmax.values.reshape(-1, 1)\n",
    "\n",
    "model.fit(sun, tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bac08d-6534-488f-9b90-e7393e30831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_, model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6213bfb7-3a1a-41f9-b96d-64c4c16077f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.arange(0, 301, 50)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "ax.plot(sun, tmax, 'k.', label='data')\n",
    "ax.plot(xx, model.predict(xx.reshape(-1, 1)), 'r--', label='linear fit')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "ax.set_xlabel('hours of sun')\n",
    "ax.set_ylabel('monthly maximum temperature (degC)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65273fa6-a6ff-4b08-921d-fecd025de010",
   "metadata": {},
   "source": [
    "## loss functions\n",
    "\n",
    "$$ MSE = \\frac{1}{N} \\sum_i (y_i - \\hat{y}_i)^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce82ec5-b39c-4746-98aa-1affac110880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the fitted parameters to get the predicted values at the input x data\n",
    "predicted = model.predict(sun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3451e4-8ee8-44fd-82bd-a1343df87bec",
   "metadata": {},
   "source": [
    "Now, let's plot the value of the loss for each input feature value, as a function of the predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c67d7f-9679-481b-97c4-92c172ce7a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate loss (residuals)\n",
    "loss = tmax - predicted\n",
    "\n",
    "fig, ax = plt.subplots(1, 1) # create a new figure and axis\n",
    "\n",
    "ax.axhline(xmin=predicted.min(), xmax=predicted.max(), color='k', linestyle='--') # plot a horizontal line at loss = 0\n",
    "ax.plot(predicted, loss, 'o') # plot the loss as a function of the predicted value\n",
    "\n",
    "ax.set_xlabel('predicted value')\n",
    "ax.set_ylabel('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605232a4-a3ad-416d-9fa0-fa1a78ad20f3",
   "metadata": {},
   "source": [
    "# gradient descent and learning\n",
    "\n",
    "\n",
    "$$ \\frac{\\partial l}{\\partial w} = \\frac{1}{N} \\sum_i -2x_i (y_i - (wx_i + b)) $$\n",
    "\n",
    "$$ \\frac{\\partial l}{\\partial b} = \\frac{1}{N} \\sum_i -2(y_i - (wx_i + b)) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2281132f-700a-4196-8ef5-5566e86b67bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(xdata, ydata, w, b, learning_rate):\n",
    "    dl_dw = (-2 * xdata * (ydata - (w * xdata + b))).mean() # calculate the partial derivative of l wrt w\n",
    "    dl_db = (-2 * (ydata - (w * xdata + b))).mean() # calculate the partial derivative of l wrt b\n",
    "\n",
    "    w -= dl_dw * learning_rate # subtract dl/dw * learning_rate from w\n",
    "    b -= dl_db * learning_rate # subtract dl/db * learning_rate from b\n",
    "\n",
    "    return w, b # return the updated values of w and b\n",
    "\n",
    "\n",
    "def avg_loss(xdata, ydata, w, b):\n",
    "    loss = (ydata - (w * xdata + b))**2 \n",
    "    return loss.mean()    \n",
    "\n",
    "\n",
    "def train(xdata, ydata, w, b, learning_rate, epochs, verbose=True, plot=True):\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for ee in range(epochs):\n",
    "        w, b = update_parameters(xdata, ydata, w, b, learning_rate)\n",
    "\n",
    "        if ee % 10 == 0:\n",
    "            # if verbose:\n",
    "            #    print(f\"epoch: {ee}, loss: {avg_loss(xdata, ydata, w, b):.2f}\")\n",
    "            df.loc[ee, 'weight'] = w\n",
    "            df.loc[ee, 'bias'] = b\n",
    "            df.loc[ee, 'avg_loss'] = avg_loss(xdata, ydata, w, b)\n",
    " \n",
    "    df.loc[ee, 'weight'] = w\n",
    "    df.loc[ee, 'bias'] = b\n",
    "    df.loc[ee, 'avg_loss'] = avg_loss(xdata, ydata, w, b)\n",
    "\n",
    "    if plot:\n",
    "        ax = df.reset_index(names='epoch').plot('epoch', 'avg_loss', legend=False)\n",
    "        ax.set_ylabel('average loss')\n",
    "        \n",
    "    \n",
    "    return df.reset_index(names=['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199bd052-a91b-4d8d-b42e-bbfaadda2d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "test = train(sun, tmax, w=0, b=0, learning_rate=1e-7, epochs=1000)\n",
    "\n",
    "test.tail(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92df1f6-c6b0-4360-a3ba-71ba6381ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train(sun, tmax, w=0, b=0, learning_rate=1e-6, epochs=10000)\n",
    "\n",
    "test.tail(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244a0398-277e-43c0-8c0c-f06bff912c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train(sun, tmax, w=0, b=0, learning_rate=1e-5, epochs=10000)\n",
    "\n",
    "test.tail(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a82e4e9-82f8-49f2-8e63-4cd6880cf896",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train(sun, tmax, w=0, b=0, learning_rate=1e-4, epochs=100, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8b1efa-ba18-4112-ace8-542ab018a3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
